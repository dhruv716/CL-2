{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/dhruvpai/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dhruvpai/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text document\n",
    "text = \"\"\"Natural language processing (NLP) is a field of artificial intelligence that enables computers to understand, interpret, and generate human language. It combines computational linguistics with machine learning to process and analyze large amounts of natural language data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the text into words\n",
    "words = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming using PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in filtered_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:  Natural language processing (NLP) is a field of artificial intelligence that enables computers to understand, interpret, and generate human language. It combines computational linguistics with machine learning to process and analyze large amounts of natural language data.\n",
      "\n",
      "Tokenized Words:  ['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'field', 'of', 'artificial', 'intelligence', 'that', 'enables', 'computers', 'to', 'understand', ',', 'interpret', ',', 'and', 'generate', 'human', 'language', '.', 'It', 'combines', 'computational', 'linguistics', 'with', 'machine', 'learning', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.']\n",
      "\n",
      "Filtered Words (Stopwords Removed):  ['Natural', 'language', 'processing', '(', 'NLP', ')', 'field', 'artificial', 'intelligence', 'enables', 'computers', 'understand', ',', 'interpret', ',', 'generate', 'human', 'language', '.', 'combines', 'computational', 'linguistics', 'machine', 'learning', 'process', 'analyze', 'large', 'amounts', 'natural', 'language', 'data', '.']\n",
      "\n",
      "Stemmed Words:  ['natur', 'languag', 'process', '(', 'nlp', ')', 'field', 'artifici', 'intellig', 'enabl', 'comput', 'understand', ',', 'interpret', ',', 'gener', 'human', 'languag', '.', 'combin', 'comput', 'linguist', 'machin', 'learn', 'process', 'analyz', 'larg', 'amount', 'natur', 'languag', 'data', '.']\n"
     ]
    }
   ],
   "source": [
    "# Output the processed words\n",
    "print(\"Original Text: \", text)\n",
    "print(\"\\nTokenized Words: \", words)\n",
    "print(\"\\nFiltered Words (Stopwords Removed): \", filtered_words)\n",
    "print(\"\\nStemmed Words: \", stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the Code:\n",
    "-----\n",
    "\n",
    "Import Libraries:\n",
    "We import necessary modules from the nltk library: stopwords, word_tokenize, and PorterStemmer.\n",
    "\n",
    "Download Required NLTK Data:\n",
    "We download the required NLTK data files (punkt for tokenization and stopwords for a list of stop words).\n",
    "\n",
    "Sample Text:\n",
    "A sample text document is provided that discusses Natural Language Processing (NLP).\n",
    "\n",
    "Tokenization:\n",
    "The word_tokenize() function is used to break the text into individual words (tokens).\n",
    "\n",
    "Stop Word Removal:\n",
    "A list of common stop words in English is obtained using stopwords.words('english').\n",
    "The list of words is filtered to remove any stop words, resulting in a list of words without common non-informative terms like \"the\", \"and\", etc.\n",
    "\n",
    "Stemming:\n",
    "The PorterStemmer class is used to reduce words to their root forms. For example, \"running\" becomes \"run\", and \"better\" becomes \"better\".\n",
    "\n",
    "Output:\n",
    "The original text, tokenized words, filtered (stopword removed) words, and stemmed words are printed to the console.\n",
    "\n",
    "Questions:\n",
    "----\n",
    "\n",
    "1. What are the different NLTK libraries?\n",
    "NLTK provides a variety of modules and tools for text processing, including:\n",
    "nltk.corpus: For accessing datasets like stopwords, movie reviews, etc.\n",
    "nltk.tokenize: For splitting text into sentences and words.\n",
    "nltk.stem: For stemming and lemmatization algorithms (e.g., PorterStemmer, WordNetLemmatizer).\n",
    "nltk.chat: For building simple chatbots.\n",
    "nltk.probability: For statistical modeling.\n",
    "nltk.parse: For parsing text into syntactic structures.\n",
    "And many more for various natural language processing tasks.\n",
    "\n",
    "2. How to remove stop words from the file?\n",
    "To remove stop words in NLTK, you can:\n",
    "Tokenize the text using nltk.tokenize.word_tokenize().\n",
    "Load a list of stop words using nltk.corpus.stopwords.words('english').\n",
    "Filter out the stop words by checking if each token is in the list of stop words.\n",
    "\n",
    "3. What is meant by stemming?\n",
    "Stemming is the process of reducing words to their base or root form by removing prefixes or suffixes. For instance, \"running\" becomes \"run\", and \"better\" remains \"better\" in some cases. The goal is to reduce words to a common base to treat similar words equally.\n",
    "\n",
    "4. What is meant by Lemmatization?\n",
    "Lemmatization is the process of reducing a word to its base or dictionary form (called a \"lemma\"). Unlike stemming, which simply chops off word endings, lemmatization takes into account the word's meaning and context. For example, \"running\" becomes \"run\", but \"better\" would become \"good\" through lemmatization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0b15402db86e3924a8be0f40e4477bbc39fc6773c61cc56d96ddc22ec1bec37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
